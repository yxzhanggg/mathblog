<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="shortcut icon" href="/mathblog/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/mathblog/assets/css/just-the-docs-default.css"> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-2709176-10"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-2709176-10', { 'anonymize_ip': true }); </script> <script type="text/javascript" src="/mathblog/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="/mathblog/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>What is matrix (Ax = b) | Yaoxin’s Notes</title><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="What is matrix (Ax = b)" /><meta property="og:locale" content="en_US" /><link rel="canonical" href="http://localhost:4000/mathblog/docs/Linear-Algebra/Fundamentals/" /><meta property="og:url" content="http://localhost:4000/mathblog/docs/Linear-Algebra/Fundamentals/" /><meta property="og:site_name" content="Yaoxin’s Notes" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="What is matrix (Ax = b)" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","headline":"What is matrix (Ax = b)","url":"http://localhost:4000/mathblog/docs/Linear-Algebra/Fundamentals/"}</script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], inlineMath: [['$','$']] } }); </script> <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], inlineMath: [['$','$']] } }); </script> <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script><body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg><div class="side-bar"><div class="site-header"> <a href="http://localhost:4000/mathblog/" class="site-title lh-tight"> Yaoxin's Notes </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a></div><nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/mathblog/" class="nav-list-link">Home</a><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/mathblog/docs/Fundamentals" class="nav-list-link">Fundamentals</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Fundamental/Logic/" class="nav-list-link">Logic</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Fundamental/Complex-Numbers/" class="nav-list-link">Complex Numbers</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Fundamental/Norms/" class="nav-list-link">Norms</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Fundamental/Mechanics/" class="nav-list-link">Mechanics</a></ul><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/mathblog/docs/Linear-Algebra" class="nav-list-link">Linear Algebra</a><ul class="nav-list "><li class="nav-list-item active"><a href="http://localhost:4000/mathblog/docs/Linear-Algebra/Fundamentals/" class="nav-list-link active">What is matrix (Ax = b)</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Linear-Algebra/Spaces/" class="nav-list-link">Spaces</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Linear-Algebra/Orthogonality/" class="nav-list-link">Orthogonality</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Linear-Algebra/Eigen/" class="nav-list-link">Eigens</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Linear-Algebra/SVD/" class="nav-list-link">SVD</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Linear-Algebra/Transformation/" class="nav-list-link">Transformation</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Linear-Algebra/Complex/" class="nav-list-link">Complex</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Linear-Algebra/App/" class="nav-list-link">Applications</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Linear-Algebra/Num/" class="nav-list-link">Numerical</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Linear-Algebra/PS/" class="nav-list-link">Probability & Statistics</a></ul><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/mathblog/docs/Info-Prob" class="nav-list-link">Information and Probability</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Info-Prob/Com/" class="nav-list-link">Communication</a></ul><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/mathblog/docs/Signals-Systems" class="nav-list-link">Signals and Systems</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Signals-Systems/Fundamentals/" class="nav-list-link">Fundamentals</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Signals-Systems/Transformations/" class="nav-list-link">Transformations</a><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Signals-Systems/Process%20Dynamics%20and%20Control/" class="nav-list-link">Process Dynamics and Control</a></ul><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/mathblog/docs/Convex-Optimization" class="nav-list-link">Convex Optimization</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Convex-Optimization/Convex-set/" class="nav-list-link">Convex set</a></ul><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/mathblog/docs/Machine-Learning" class="nav-list-link">Machine Learning</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/mathblog/docs/Machine-Learning/SuLearning/" class="nav-list-link">x</a></ul></ul></nav><footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Yaoxin's Notes" aria-label="Search Yaoxin's Notes" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div></div><div id="main-content-wrap" class="main-content-wrap"><nav aria-label="Breadcrumb" class="breadcrumb-nav"><ol class="breadcrumb-nav-list"><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/mathblog/docs/Linear-Algebra">Linear Algebra</a><li class="breadcrumb-nav-list-item"><span>What is matrix (Ax = b)</span></ol></nav><div id="main-content" class="main-content" role="main"><h1 id="basics"> <a href="#basics" class="anchor-heading" aria-labelledby="basics"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Basics</h1><h4 id="vector"> <a href="#vector" class="anchor-heading" aria-labelledby="vector"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> vector</h4><p>A vector in $n$ dimension space has $n$ components $v_1, v_2,\ldots,v_n$.</p>\[\boldsymbol{v}+\boldsymbol{w}=\left(v_{1}+w_{1}, v_{2}+w_{2}\right)\] \[c \boldsymbol{v}=\left(c v_{1}, c v_{2}\right)\]<h4 id="length-of-a-vector"> <a href="#length-of-a-vector" class="anchor-heading" aria-labelledby="length-of-a-vector"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Length of a vector</h4>\[\text { length }=\|\boldsymbol{v}\|=\sqrt{\boldsymbol{v} \cdot \boldsymbol{v}}=\left(v_{1}^{2}+v_{2}^{2}+\cdots+v_{n}^{2}\right)^{1 / 2}\]<h4 id="linear-combination"> <a href="#linear-combination" class="anchor-heading" aria-labelledby="linear-combination"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Linear combination</h4>\[c \boldsymbol{u}+d \boldsymbol{v}+e \boldsymbol{w}\]<h4 id="cosine-formula"> <a href="#cosine-formula" class="anchor-heading" aria-labelledby="cosine-formula"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Cosine formula</h4>\[\cos \theta=\frac{\boldsymbol{v} \cdot \boldsymbol{w}}{\|\boldsymbol{v}\|\|\boldsymbol{w}\|}\]<h4 id="schwarz-inequality"> <a href="#schwarz-inequality" class="anchor-heading" aria-labelledby="schwarz-inequality"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Schwarz inequality</h4>\[\|\boldsymbol{v} \cdot \boldsymbol{w}\| \leq{\|\boldsymbol{v}\|\|\boldsymbol{w}\|}\]<h4 id="triangle-inequality"> <a href="#triangle-inequality" class="anchor-heading" aria-labelledby="triangle-inequality"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Triangle Inequality</h4>\[\|\boldsymbol{v}+\boldsymbol{w}\| \leq\|\boldsymbol{v}\|+\|\boldsymbol{w}\|\]<h1 id="different-viewpoints"> <a href="#different-viewpoints" class="anchor-heading" aria-labelledby="different-viewpoints"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Different viewpoints</h1><h4 id="row-picture"> <a href="#row-picture" class="anchor-heading" aria-labelledby="row-picture"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Row picture</h4>\[\begin{aligned} x-2 y &amp;=1 \\ 3 x+2 y &amp;=11 \end{aligned}\]<p>The <strong>row picture</strong> shows two lines meeting at a single point (the solution).</p><p><img src="https://live.staticflickr.com/65535/52144395134_e9909f4531_o.png" alt="Screen Shot 2022-06-13 at 22.00.48" /></p><h4 id="column-picture"> <a href="#column-picture" class="anchor-heading" aria-labelledby="column-picture"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Column picture</h4>\[\left[\begin{array}{rr} 1 &amp; -2 \\ 3 &amp; 2 \end{array}\right]\left[\begin{array}{l} 3 \\ 1 \end{array}\right]=\left[\begin{array}{r} 1 \\ 11 \end{array}\right]\]<p>The <strong>column picture</strong> combines the column vectors on the left side to produce the vector b on the right side.</p><p><img src="https://live.staticflickr.com/65535/52144183903_039eee5beb_o.png" alt="Screen Shot 2022-06-13 at 22.03.47" /></p><h4 id="hyperplane"> <a href="#hyperplane" class="anchor-heading" aria-labelledby="hyperplane"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Hyperplane</h4><p>the plane $n&gt;3$</p><h1 id="matrix-multiplication"> <a href="#matrix-multiplication" class="anchor-heading" aria-labelledby="matrix-multiplication"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Matrix multiplication</h1><h4 id="direct-method"> <a href="#direct-method" class="anchor-heading" aria-labelledby="direct-method"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Direct method</h4><p>The entry in row $i$ and column $j$ of $A B$ is $($ row $i$ of $A) \cdot($ column $j$ of $B)$.</p><p><img src="https://live.staticflickr.com/65535/52146378173_1a6be3cdab_o.png" alt="Screen Shot 2022-06-14 at 18.27.10" /></p><h4 id="column-picture-1"> <a href="#column-picture-1" class="anchor-heading" aria-labelledby="column-picture-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Column picture</h4><p>Matrix $A$ times every column of $B$</p>\[A\left[\boldsymbol{b}_{1} \cdots \boldsymbol{b}_{p}\right]=\left[A \boldsymbol{b}_{1} \cdots A \boldsymbol{b}_{p}\right]\]<h4 id="row-picture-1"> <a href="#row-picture-1" class="anchor-heading" aria-labelledby="row-picture-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Row picture</h4><p>Every row of $A$ times matrix $B$</p>\[[\text { row } i \text { of } A]B=[\text { row } i \text { of } A B]\]<p>$AB= (m \times n)(n \times p) = (m \times p)$, $mp$ dot products with $n$ steps each.</p><h4 id="columns-by-rows"> <a href="#columns-by-rows" class="anchor-heading" aria-labelledby="columns-by-rows"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Columns by rows</h4><p>Multiply columns $1$ to $n$ of $A$ times rows $1$ to $n$ of $B$. Add those matrices.</p>\[\left[\begin{array}{ccc} \operatorname{col} 1 &amp; \text { col } 2 &amp; \text { col 3} \\ \cdot &amp; \cdot &amp; \cdot \\ \cdot &amp; \cdot &amp; \cdot \end{array}\right]\left[\begin{array}{ccc} \text { row 1 } &amp; \cdots \cdot \\ \text { row 2 } &amp; \cdots \cdot \\ \text { row } 3 &amp; \cdots \cdot \end{array}\right]=(\operatorname{col} 1)(\text { row 1) }+(\operatorname{col} 2)(\text { row 2) }+(\operatorname{col} 3)(\text { row 3) }\]<h4 id="schur-complement"> <a href="#schur-complement" class="anchor-heading" aria-labelledby="schur-complement"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Schur complement</h4>\[S=D-C A^{-1} B\] \[\left[\begin{array}{c|c} I &amp; \mathbf{0} \\ \hline-C A^{-1} &amp; I \end{array}\right]\left[\begin{array}{c|c} A &amp; B \\ \hline C &amp; D \end{array}\right]=\left[\begin{array}{c|c} A &amp; B \\ \hline \mathbf{0} &amp; \boldsymbol{D}-\boldsymbol{C A}^{-\mathbf{1}} \boldsymbol{B} \end{array}\right]\]<h1 id="inversion"> <a href="#inversion" class="anchor-heading" aria-labelledby="inversion"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Inversion</h1><h4 id="inverse-matrix"> <a href="#inverse-matrix" class="anchor-heading" aria-labelledby="inverse-matrix"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Inverse matrix</h4><p>The matrix $A$ is invertible if there exists a matrix $A^{-1}$ that “inverts” $A$:</p>\[A^{-1} A=I \quad \text { and } \quad A A^{-1}=I\]<ul><li>Two-sided inversion: square matrix<li>One-sided inversion: rectangular matrix</ul><h4 id="inversibility"> <a href="#inversibility" class="anchor-heading" aria-labelledby="inversibility"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Inversibility</h4><p>The inverse exists if and only if <strong>elimination</strong> produces $n$ pivots.</p><h5 id="properties"> <a href="#properties" class="anchor-heading" aria-labelledby="properties"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Properties</h5><ol><li><p>$(A B C)^{-1}=C^{-1} B^{-1} A^{-1}$</p><li><p>$K$ is symmetric across its main diagonal. Then $K^{-1}$ is also symmetric.</p><li><p>$K$ is tridiagonal (only three nonzero diagonals = band). But $K^{-1}$ is a dense matrix with no zeros.</p><li><p>An invertible matrix cannot have a zero determinant.</p><li><p>If $A$ is invertible and upper triangular, so is $A^{-1}$. Start with $A A^{-1}=I$.</p><li><p>Diagonally dominant matrices are invertible:</p>\[\left|\boldsymbol{a}_{i i}\right|&gt;\sum_{j \neq i}\left|\boldsymbol{a}_{i j}\right|\]</ol><p>For <strong>elimination matrix</strong> $E$</p><p><img src="https://live.staticflickr.com/65535/52171580522_a0f5588f13_o.png" alt="Screen Shot 2022-06-25 at 22.59.14" /></p><h4 id="gauss-jordan-method"> <a href="#gauss-jordan-method" class="anchor-heading" aria-labelledby="gauss-jordan-method"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Gauss-Jordan method</h4><p>The Gauss-Jordan method computes $A^{-1}$ by solving all $n$ equations together.</p>\[A A^{-1}=A\left[\begin{array}{lll} x_{1} &amp; x_{2} &amp; x_{3} \end{array}\right]=\left[\begin{array}{lll} e_{1} &amp; e_{2} &amp; e_{3} \end{array}\right]=I\] \[A^{-1}\left[\begin{array}{ll} A &amp; I \end{array}\right]=E\left[\begin{array}{ll} A &amp; I \end{array}\right]=\left[\begin{array}{ll} I &amp; A^{-1} \end{array}\right]\]<p>The matrix $E$ keeps a record.</p><h4 id="from-cofactor-matrix"> <a href="#from-cofactor-matrix" class="anchor-heading" aria-labelledby="from-cofactor-matrix"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> From Cofactor matrix</h4>\[\left(A^{-1}\right)_{i j}=\frac{C_{j i}}{\operatorname{det} A} \quad \text { and } \quad A^{-1}=\frac{C^{\mathrm{T}}}{\operatorname{det} A}\]<h1 id="transpose-and-permutation"> <a href="#transpose-and-permutation" class="anchor-heading" aria-labelledby="transpose-and-permutation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Transpose and Permutation</h1><h4 id="transpose"> <a href="#transpose" class="anchor-heading" aria-labelledby="transpose"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Transpose</h4>\[\text{row}\leftrightarrow\text{column} \quad \left(A^{\mathbf{T}}\right)_{i j}=A_{j i}\]<p>Mathematical definition: $A^{\mathrm{T}}$ is the matrix that makes these two inner products equal for every $x$ and $y$:</p>\[(A x)^{\mathrm{T}} y=x^{\mathrm{T}}\left(A^{\mathrm{T}} y\right) \quad \text { Inner product of } A x \text { with } y=\text { Inner product of } x \text { with } A^{\mathrm{T}} y\]<h5 id="properties-1"> <a href="#properties-1" class="anchor-heading" aria-labelledby="properties-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Properties</h5><ol><li><p>SUM: The transpose of $A+B$ is $A^{\mathrm{T}}+B^{\mathrm{T}}$.</p><li><p>PRODUCT: $(A B C)^{T}=C^{T}B^{T}A^{T}$.</p><p>$A \boldsymbol{x}$ combines the columns of $A$ while $\boldsymbol{x}^{\mathrm{T}} A^{\mathrm{T}}$ combines the rows of $A^{\mathrm{T}}$ .</p><li><p>INVERSE: The transpose of $A^{-1}$ is $\left(A^{-1}\right)^{\mathrm{T}}=\left(A^{\mathrm{T}}\right)^{-1}$.</p><li><p>$A^{\mathrm{T}}$ is invertible exactly when $A$ is invertible.</p><li><p>$A^\mathrm{T} A$ is invertible if and only if $A$ has linearly independent columns.</p><li><p>$A^{\mathrm{T}} A$ is symmetric.</p><li><p>Transformation perspective: transpose matrix is an n-dimensional scissors.</p></ol><h4 id="inner-products--dot-product-mathbft-is-inside"> <a href="#inner-products--dot-product-mathbft-is-inside" class="anchor-heading" aria-labelledby="inner-products--dot-product-mathbft-is-inside"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Inner products / Dot product ($^\mathbf{T}$ is inside)</h4>\[x^{\mathrm{T}} y \quad(1 \times n)(n \times 1)\]<h4 id="outer-products--rank-one-product-mathbft-is-inside"> <a href="#outer-products--rank-one-product-mathbft-is-inside" class="anchor-heading" aria-labelledby="outer-products--rank-one-product-mathbft-is-inside"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Outer products / Rank one product ($^\mathbf{T}$ is inside)</h4>\[x y^{\mathrm{T}} \quad(n \times 1)(1 \times n)\]<h4 id="symmetric-matrix"> <a href="#symmetric-matrix" class="anchor-heading" aria-labelledby="symmetric-matrix"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Symmetric Matrix</h4><p>Definition: A symmetric matrix has $S^{\mathrm{T}}=S .$ This means that $s_{j i}=s_{i j}$.</p><h5 id="properties-2"> <a href="#properties-2" class="anchor-heading" aria-labelledby="properties-2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Properties</h5><p>The inverse of a symmetric matrix is also symmetric. $\left(S^{-1}\right)^{\mathrm{T}}=\left(S^{\mathrm{T}}\right)^{-1}=S^{-1}$</p><h4 id="samathrmt-a"> <a href="#samathrmt-a" class="anchor-heading" aria-labelledby="samathrmt-a"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> $S=A^{\mathrm{T}} A$</h4><p>The transpose of $A^{\mathrm{T}} A$ is $A^{\mathrm{T}}\left(A^{\mathrm{T}}\right)^{\mathrm{T}}$ which is $A^{\mathrm{T}} A$ again.</p><h4 id="permutation-matrix"> <a href="#permutation-matrix" class="anchor-heading" aria-labelledby="permutation-matrix"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Permutation Matrix</h4><p>Definition: A permutation matrix $P$ has the rows of the identity $I$ in any order.</p>\[P P^{\mathrm{T}}=I \leftrightarrow P^{\mathrm{T}}=P^{-1}\]<h4 id="palu-quad--quad-alpu"> <a href="#palu-quad--quad-alpu" class="anchor-heading" aria-labelledby="palu-quad--quad-alpu"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> $PA=LU \quad / \quad A=LPU$</h4><p>When there is a row exchange, the sign of determinant is reversed.</p><h1 id="determinant"> <a href="#determinant" class="anchor-heading" aria-labelledby="determinant"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Determinant</h1>\[\begin{aligned} &amp;\text {The determinant of an } n \text { by } n \text { matrix can be found in three ways: }\\ &amp;\begin{array}{ll} 1 \text { Multiply the } n \text { pivots (times } 1 \text { or }-1) &amp; \text { This is the pivot formula. } \\ 2 \text { Add up } n \text { ! terms (times } 1 \text { or }-1) &amp; \text { This is the "big' formula. } \\ \mathbf{3} \text { Combine } n \text { smaller determinants (times } 1 \text { or }-1 \text { ) } &amp; \text { This is the cofactor formula. } \end{array} \end{aligned}\]<h2 id="properties-3"> <a href="#properties-3" class="anchor-heading" aria-labelledby="properties-3"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Properties</h2>\[\operatorname{det} A \text { and }|A|\]<ol><li><p>The determinant of the $n$ by $n$ identity matrix is $1 .$</p><li><p>The determinant changes sign when two rows are exchanged (sign reversal):</p><li><p>The determinant is a linear function of each row separately (all other rows stay fixed).</p><p><img src="https://live.staticflickr.com/65535/52201208012_3ee0721520_o.png" alt="Screen Shot 2022-07-08 at 3.19.48 PM" /></p><li>4 If two rows of $A$ are equal, then $\operatorname{det} A=0$.<li>Subtracting a multiple of one row from another row leaves $\operatorname{det} A$ unchanged.<li>A matrix with a row of zeros has $\operatorname{det} A=0$.<li>If $A$ is triangular then $\operatorname{det} A=a_{11} a_{22} \cdots a_{n n}= \text{product of diagonal entries}$.<li>If $A$ is singular then $\operatorname{det} A=0$. If $A$ is invertible then $\operatorname{det} A \neq 0$.<li>The determinant of $A B$ is $\operatorname{det} A$ times $\operatorname{det} B:|A B|=|A||B|$.<li> \[A^{\mathrm{T}}=\operatorname{det} A\]</ol><h2 id="calculate-the-determinant"> <a href="#calculate-the-determinant" class="anchor-heading" aria-labelledby="calculate-the-determinant"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Calculate the determinant</h2><h4 id="the-pivot-formula"> <a href="#the-pivot-formula" class="anchor-heading" aria-labelledby="the-pivot-formula"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Pivot Formula</h4>\[\operatorname{det} A=(\operatorname{det} L)(\operatorname{det} U)=(1)\left(d_{1} d_{2} \cdots d_{n}\right)\]<p>Pivots from determinants:</p><p>The $k$ th pivot is $\boldsymbol{d}<em>{\boldsymbol{k}}=\frac{d</em>{1} d_{2} \cdots d_{k}}{d_{1} d_{2} \cdots d_{k-1}}=\frac{\operatorname{det} A_{k}}{\operatorname{det} A_{k-1}}$.</p><h4 id="the-big-formula-for-determinants"> <a href="#the-big-formula-for-determinants" class="anchor-heading" aria-labelledby="the-big-formula-for-determinants"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Big Formula for Determinants</h4><p>$\operatorname{det} A=$ sum over all $\mathbf{n} !$ column permutations $P=(\alpha, \beta, \ldots, \omega)$ \(=\sum(\operatorname{det} P) a_{1 \alpha} a_{2 \beta} \cdots a_{n \omega}=\text { BIG FORMULA. }\)</p><h4 id="determinant-by-cofactors"> <a href="#determinant-by-cofactors" class="anchor-heading" aria-labelledby="determinant-by-cofactors"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Determinant by Cofactors</h4><p>The determinant is the dot product of any row $i$ of $A$ with its cofactors using other rows: COFACTOR FORMULA \(\operatorname{det} A=a_{i 1} C_{i 1}+a_{i 2} C_{i 2}+\cdots+a_{i n} C_{i n} \text {. }\) Each cofactor $C_{i j}$ (order $n-1$, without row $i$ and column $j$ ) includes its correct sign: Cofactor $C_{i j}=(-1)^{i+j} \operatorname{det} M_{i j}$</p><h1 id="solving"> <a href="#solving" class="anchor-heading" aria-labelledby="solving"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Solving</h1><h4 id="elimination"> <a href="#elimination" class="anchor-heading" aria-labelledby="elimination"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Elimination</h4><p>To <strong>eliminate</strong> $x$: Subtract a multiple of equation $1$ from equation $2$.</p><p><strong>Pivot</strong> = first nonzero in the row that does the elimination</p><p><strong>Multiplier</strong> = (entry to eliminate) divided by (pivot) = $\ell_{i j}=\frac{\text { entry to eliminate in row } i}{\text { pivot in row } j}$</p><p><img src="https://live.staticflickr.com/65535/52144200581_0e7dc90af3_o.png" alt="Screen Shot 2022-06-13 at 22.19.20" /></p><h5 id="possible-result"> <a href="#possible-result" class="anchor-heading" aria-labelledby="possible-result"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Possible result</h5><ol><li><p>Permanent failure with no solution.<img src="https://live.staticflickr.com/65535/52144226868_1a0fc2ddbd_o.png" alt="Screen Shot 2022-06-13 at 22.21.18" /></p><li><p>Failure with infinitely many solutions.</p></ol><p><img src="https://live.staticflickr.com/65535/52196122935_d6b8d13a41_o.png" alt="Screen Shot 2022-07-05 at 3.38.19 PM" /></p><h4 id="a--lu"> <a href="#a--lu" class="anchor-heading" aria-labelledby="a--lu"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> $A = LU$</h4><p>This is elimination without row exchanges. The multipliers $l_{ij}$ are below the diagonal of $L$.</p><h5 id="elimination-factorization"> <a href="#elimination-factorization" class="anchor-heading" aria-labelledby="elimination-factorization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Elimination: factorization</h5>\[A=L U=\text { (lower triangular) (upper triangular) }=(E_1^{-1}E_2^{-1}\ldots E_n^{-1})U\]<p>Elimination on $A$ requires about $\frac{1}{3} n^{3}$ multiplications and $\frac{1}{3} n^{3}$ subtractions.</p><h5 id="substitution-solve"> <a href="#substitution-solve" class="anchor-heading" aria-labelledby="substitution-solve"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Substitution: solve</h5>\[\text { Forward and backward: Solve } \quad L c=b \quad \text { and then solve } \quad U x=c\]<p>Each right side $b/c$ needs $n^{2}$ multiplications and $n^{2}$ subtractions.</p><ul><li>Band matrix $B$ (with $w$ nonzero diagonals)</ul><p>$A$ to $U$: $\frac{1}{3} n^{3}$ reduces to $n w^{2}$</p><p>Solve: $n^{2}$ reduces to $2 n w$</p><h4 id="a--ldu"> <a href="#a--ldu" class="anchor-heading" aria-labelledby="a--ldu"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> $A = LDU$</h4>\[\text { Split } U \text { into }\left[\begin{array}{llll} d_{1} &amp; &amp; &amp; \\ &amp; d_{2} &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; d_{n} \end{array}\right]\left[\begin{array}{cccc} 1 &amp; u_{12} / d_{1} &amp; u_{13} / d_{1} &amp; \cdot \\ &amp; 1 &amp; u_{23} / d_{2} &amp; \cdot \\ &amp; &amp; \ddots &amp; \vdots \\ &amp; &amp; &amp; 1 \end{array}\right]\]<h4 id="sldlmathrmt"> <a href="#sldlmathrmt" class="anchor-heading" aria-labelledby="sldlmathrmt"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> $S=LDL^{\mathrm{T}}$</h4><p>If $S=S^{\mathrm{T}}$ is factored into $L D U$ with no row exchanges, then $U$ is exactly $L^{\mathrm{T}}$.</p><h4 id="a--lpu"> <a href="#a--lpu" class="anchor-heading" aria-labelledby="a--lpu"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> $A = LPU$</h4><p>permutation</p><h4 id="inversion-1"> <a href="#inversion-1" class="anchor-heading" aria-labelledby="inversion-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Inversion</h4>\[\text { Multiply } A x=b \text { by } A^{-1} \text {. Then } x=A^{-1} A x=A^{-1} b \text {. }\]<h4 id="cramers-rule"> <a href="#cramers-rule" class="anchor-heading" aria-labelledby="cramers-rule"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Cramer’s Rule</h4><p>explicit formula but huge complexity $(n+1) !$</p><p>If $\operatorname{det} A$ is not zero, $A \boldsymbol{x}=\boldsymbol{b}$ is solved by determinants: \(x_{1}=\frac{\operatorname{det} B_{1}}{\operatorname{det} A} \quad x_{2}=\frac{\operatorname{det} B_{2}}{\operatorname{det} A} \quad \ldots \quad x_{n}=\frac{\operatorname{det} B_{n}}{\operatorname{det} A}\) The matrix $B_{j}$ has the jth column of A replaced by the vector $b$.</p><p>Set $B=I$ we can find inverse matrix.</p>\[[A]\left[\begin{array}{lll} \boldsymbol{x}_{1} &amp; 0 &amp; 0 \\ \boldsymbol{x}_{2} &amp; 1 &amp; 0 \\ \boldsymbol{x}_{3} &amp; 0 &amp; 1 \end{array}\right]=\left[\begin{array}{lll} \boldsymbol{b}_{\mathbf{1}} &amp; a_{12} &amp; a_{13} \\ \boldsymbol{b}_{\mathbf{2}} &amp; a_{22} &amp; a_{23} \\ \boldsymbol{b}_{\mathbf{3}} &amp; a_{32} &amp; a_{33} \end{array}\right]=B_{1}\] \[(\operatorname{det} A)\left(x_{1}\right)=\operatorname{det} B_{1} \quad \text { or } \quad x_{1}=\frac{\operatorname{det} B_{1}}{\operatorname{det} A} .\]<p>Take determinants of the three matrices to find $x_1$:</p><p>Product rule \((\operatorname{det} A)\left(x_{1}\right)=\operatorname{det} B_{1} \quad \text { or } \quad x_{1}=\frac{\operatorname{det} B_{1}}{\operatorname{det} A}\)</p><h1 id="derivative-a"> <a href="#derivative-a" class="anchor-heading" aria-labelledby="derivative-a"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Derivative $A$</h1><h4 id="inner-product-of-functions"> <a href="#inner-product-of-functions" class="anchor-heading" aria-labelledby="inner-product-of-functions"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Inner product of functions</h4><ol><li> \[x^{\mathbf{T}} y=(x, y)=\int_{-\infty}^{\infty} x(t) y(t) d t\]<li> \[(A \boldsymbol{x})^{\mathrm{T}} \boldsymbol{y}=\boldsymbol{x}^{\mathrm{T}}\left(A^{\mathrm{T}} \boldsymbol{y}\right)\]<li> \[(A x, y)=\int_{-\infty}^{\infty} \frac{d x}{d t} y(t) d t=\int_{-\infty}^{\infty} x(t)\left(-\frac{d y}{d t}\right) d t=\left(x, A^{\mathrm{T}} y\right)\]</ol><p>the transpose of the derivative is minus the derivative</p>\[A=d / d t \quad A^{\mathrm{T}}=-d / d t\]<h4 id="forward-difference-matrix-to-backward-difference-matrix"> <a href="#forward-difference-matrix-to-backward-difference-matrix" class="anchor-heading" aria-labelledby="forward-difference-matrix-to-backward-difference-matrix"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Forward difference matrix to backward difference matrix</h4>\[A=\left[\begin{array}{rrrr} 0 &amp; 1 &amp; 0 &amp; 0 \\ -1 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; -1 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; -1 &amp; 0 \end{array}\right] \quad \text { transposes to } \quad A^{\mathrm{T}}=\left[\begin{array}{rrrr} 0 &amp; -1 &amp; 0 &amp; 0 \\ 1 &amp; 0 &amp; -1 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; -1 \\ 0 &amp; 0 &amp; 1 &amp; 0 \end{array}\right]=-A\]<ul><li>1st derivative is antisymmetric<li>2st derivative as symmetric</ul><h1 id="cross-product"> <a href="#cross-product" class="anchor-heading" aria-labelledby="cross-product"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Cross Product</h1><p><img src="https://live.staticflickr.com/65535/52203010674_da70e69066_o.png" alt="Screen Shot 2022-07-08 at 8.28.32 PM" /></p>\[\|\boldsymbol{u} \times \boldsymbol{v}\|=\|\boldsymbol{u}\|\|\boldsymbol{v}\||\sin \theta| \quad \text { and } \quad|\boldsymbol{u} \cdot \boldsymbol{v}|=\|\boldsymbol{u}\|\|\boldsymbol{v}\||\cos \theta|\]<p><img src="https://live.staticflickr.com/65535/52202748236_4471781510_o.png" alt="Screen Shot 2022-07-08 at 8.32.14 PM" /></p><p><img src="https://live.staticflickr.com/65535/52202750006_a2f5cbf4bf_o.png" alt="Screen Shot 2022-07-08 at 8.33.19 PM" /></p><h4 id="turning-force-or-torque"> <a href="#turning-force-or-torque" class="anchor-heading" aria-labelledby="turning-force-or-torque"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> turning force or torque</h4>\[u \times F\]<p>position of a mass: $\left(u_{1}, u_{2}, u_{3}\right)$</p><p>force acting on it: $\left(F_{x}, F_{y}, F_{z}\right)$</p><h4 id="moment"> <a href="#moment" class="anchor-heading" aria-labelledby="moment"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> moment</h4><p>$|\boldsymbol{u}||\boldsymbol{F}| \sin \theta$</p><hr><footer><div class="d-flex mt-2"></div></footer></div></div><div class="search-overlay"></div></div>
